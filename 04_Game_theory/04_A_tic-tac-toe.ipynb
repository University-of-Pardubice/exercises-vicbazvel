{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5457acc-093a-4d4c-b828-b3e5d23d99b1",
   "metadata": {},
   "source": [
    "# Tic-tac-toe minmax algorithm\n",
    "We will demonstrate the minmax algorithm on a game of Tic-tac-toe played on a 3x3 game board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07f52a5e-f1a6-4381-8f90-ccc2cad21c68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f788e6",
   "metadata": {},
   "source": [
    "The State class captures the current state of the game.\n",
    "* **Attributes**\n",
    "    * gameplan - 3x3 game board with values 0 to 2\n",
    "    * player - the player who is currently on the turn\n",
    "    * current_player - the player will analyze the game and keep track of possible new states. Players take turns, so the new state should be viewed from the perspective of the opposing player. the player who is on the turn in the current state when searching the state space\n",
    "    * depth - the depth of the analyzed state\n",
    "    * max_depth - how many moves ahead the maximum is looking. If depth = max_depth, I don't analyze the game any further.\n",
    "\n",
    "* **Methods**\n",
    "    * terminal_test - method returns information whether the current state is final or not. If it is, it returns the winner.\n",
    "    * utility - the method tries to evaluate the current state from the player's perspective. In the basic version, it only distinguishes whether the player wins, doesn't win or the move doesn't lead to the end of the game.\n",
    "    * possible_actions - the method returns a list of possible moves. In the case of biscuits, this will be the coordinates of the playing area where the playing stone can be placed.\n",
    "    * expand - this method takes the current state and action definition (the coordinates where to place the die) and creates a new game state.\n",
    "    * minmax - custom implementation of the minmax algorithm\n",
    "    * next_current_player - returns the opponent to the current_player variable\n",
    "    * next_player - returns the opponents to the player variable    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3b7b390-57e3-4256-b28d-4d7d3e73a92f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class State:\n",
    "    \"\"\" Capturing the state of the game\n",
    "    gameplan - two-dimensional 3x3 array\n",
    "             - 0 - empty array\n",
    "             - 1 - X\n",
    "             - 2 - O\n",
    "    player - the player who has the turn in the game\n",
    "\n",
    "    current_player - player who is on the turn in the given state when searching the state space\n",
    "    depth - depth of the state space search\n",
    "    max_depth - maximum length of the search\n",
    "    \"\"\"\n",
    "\n",
    "    generated = 0\n",
    "\n",
    "    def __init__(self, gameplan, player, current_player=None, depth=0, max_depth=3):\n",
    "        self.gameplan = gameplan\n",
    "        self.player = player\n",
    "        if current_player is None:\n",
    "            self.current_player = player\n",
    "        else:\n",
    "            self.current_player = current_player\n",
    "        self.depth = depth\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "        State.generated += 1\n",
    "\n",
    "    def terminal_test(self):\n",
    "        \"\"\" The method tests the current state and returns a value indicating whether the game is finished and, if so, who the winner is\n",
    "\n",
    "            0 - no final status\n",
    "            1 - 1 wins\n",
    "            2 - winner 2\n",
    "        \"\"\"\n",
    "\n",
    "        # end of game rules - horizontal and vertical triplets\n",
    "        for i in range(3):\n",
    "            if np.array_equal(self.gameplan[i], [1, 1, 1]):\n",
    "                return 1\n",
    "            if np.array_equal(self.gameplan[i], [2, 2, 2]):\n",
    "                return 2\n",
    "            if np.array_equal(self.gameplan[:, i], [1, 1, 1]):\n",
    "                return 1\n",
    "            if np.array_equal(self.gameplan[:, i], [2, 2, 2]):\n",
    "                return 2\n",
    "\n",
    "        # end of game rules - diagonals\n",
    "        if np.array_equal(self.gameplan.diagonal(), [1, 1, 1]):\n",
    "            return 1\n",
    "        if np.array_equal(self.gameplan.diagonal(), [2, 2, 2]):\n",
    "            return 2\n",
    "        if np.array_equal(np.fliplr(self.gameplan).diagonal(), [1, 1, 1]):\n",
    "            return 1\n",
    "        if np.array_equal(np.fliplr(self.gameplan).diagonal(), [2, 2, 2]):\n",
    "            return 2\n",
    "\n",
    "        return 0\n",
    "\n",
    "    def utility(self, result):\n",
    "        \"\"\" The method returns an evaluation of the current state of the game\n",
    "            0 - draw\n",
    "            1 - the player who is on the turn wins\n",
    "            -1 - the opposing player wins\n",
    "        \"\"\"\n",
    "        if result == 0:\n",
    "            return 0\n",
    "        elif result == self.player:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "    def possible_actions(self):\n",
    "        \"\"\" The method returns a list of possible actions for the given state\n",
    "            The action is expressed by the coordinates of an empty playing field.\n",
    "        \"\"\"\n",
    "        possible_actions = []\n",
    "        # Finding empty playing fields\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if self.gameplan[i][j] == 0:\n",
    "                    possible_actions.append((i, j))\n",
    "        return possible_actions\n",
    "\n",
    "    def expand(self, select_action):\n",
    "        \"\"\" The method creates a new game state by applying the selected action to the current state\n",
    "\n",
    "            In the new state, the opposing player will have the turn, but the state will be evaluated from the original player's perspective\n",
    "            The depth of the searched state space will also increase\n",
    "        \"\"\"\n",
    "        if select_action[0] not in range(3):\n",
    "            return None\n",
    "        if select_action[1] not in range(3):\n",
    "            return None\n",
    "\n",
    "        # playing field must be clear\n",
    "        if self.gameplan[select_action[0], select_action[1]] != 0:\n",
    "            return None\n",
    "        \n",
    "        new_array = np.copy(self.gameplan)\n",
    "        new_array[select_action[0], select_action[1]] = self.current_player\n",
    "        return State(new_array, \n",
    "                     self.player, \n",
    "                     self.next_current_player(), \n",
    "                     self.depth + 1, \n",
    "                     max_depth=self.max_depth)\n",
    "        \n",
    "\n",
    "    def minmax(self, strategy=\"max\"):\n",
    "        \"\"\"\"\n",
    "        The method selects the one that matches the strategy from the possible actions for the given game state\n",
    "\n",
    "        stategy - what strategy will be used to select from the possible actions\n",
    "        \"\"\"\n",
    "        \n",
    "        # checking the state of the game, for a completed game the rating from the utility method is returned\n",
    "        result = self.terminal_test()\n",
    "        if result != 0:            \n",
    "            return self.utility(result), action\n",
    "        \n",
    "\n",
    "        # initialization of values for each strategy\n",
    "        if strategy == \"max\":\n",
    "            selected_utilization_value = float('-inf')\n",
    "            next_strategy = \"min\"\n",
    "        else:\n",
    "            selected_utilization_value = float('inf')\n",
    "            next_strategy = \"max\"\n",
    "\n",
    "        # finding possible moves\n",
    "        actions = self.possible_actions()\n",
    "\n",
    "        # the selected action is filled with the first action of the possible actions\n",
    "        selected_action = actions[0]\n",
    "\n",
    "        # finding the optimum action from all possible acttions\n",
    "        for action in actions:\n",
    "\n",
    "            # state expansion\n",
    "            expanded_state = self.expand(action)\n",
    "\n",
    "            #  check the game ending for expanded state\n",
    "            result = expanded_state.terminal_test()\n",
    "\n",
    "            if result != 0:\n",
    "                # games end, return status and action rating\n",
    "                return expanded_state.utility(result), action\n",
    "            else:\n",
    "                # game continues\n",
    "                # if there is at least one state in the expanded state, continue to expand the state, otherwise it's a draw\n",
    "                if len(expanded_state.possible_actions()) == 0:\n",
    "                    utilization = 0\n",
    "                else:\n",
    "                    # recursive call\n",
    "                    utilization, _ = expanded_state.minmax(next_strategy)\n",
    "\n",
    "                # according to the strategy, the evaluated action is chosen as the selected action\n",
    "                if utilization > selected_utilization_value and strategy == \"max\":\n",
    "                    selected_utilization_value = utilization\n",
    "                    selected_action = action\n",
    "                elif utilization < selected_utilization_value and strategy == \"min\":\n",
    "                    selected_utilization_value = utilization\n",
    "                    selected_action = action\n",
    "\n",
    "        return selected_utilization_value, selected_action\n",
    "\n",
    "    def next_current_player(self):\n",
    "        \"\"\" The method returns the opponent's for state space searching\n",
    "        \"\"\"\n",
    "        return 3 - self.current_player\n",
    "\n",
    "    def next_player(self):\n",
    "        \"\"\" Method returns opponent\n",
    "        \"\"\"\n",
    "        return 3 - self.player"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834e5b40",
   "metadata": {},
   "source": [
    "# Game of tic-tac-toe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b2ef5b",
   "metadata": {},
   "source": [
    "Creating the initial state of the batch\n",
    "* Game plan is empty (0)\n",
    "* Game 1 is on the turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1b4adca-e8bf-4977-a89a-bd44d5f8e602",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "state = State(gameplan=np.array([[0, 0, 0], [0, 0, 0], [0, 0, 0]]),\n",
    "              player=1, max_depth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff62ab9",
   "metadata": {},
   "source": [
    "Printing the initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55948192-1561-43f0-a580-68fb70206f09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(state.gameplan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75b01f1",
   "metadata": {},
   "source": [
    "A cycle of a game played against each other by two copies of the identical minmax algorithm\n",
    "* The game runs in a loop that ends when one of the players wins or end with drawn.\n",
    "* If the game has not ended the player on the turn using the minmax algorithm gets the turn to play\n",
    "* The player takes an action and creates a new game state\n",
    "* After the printing current state of game, the player passes the game to the opposing player.\n",
    "\n",
    "\n",
    "Keep track of time and number of states generated as the game progresses. As the game progresses, the algorithm searches a smaller state space and the turn time decreases.\n",
    "\n",
    "Since there is no constraint in the algorithm, both players play optimally. Therefore, the game ends in a draw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81b06d9a-a759-450f-922d-59515d8aac81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "Player 1\n",
      "Select action: (0, 0)\n",
      "[[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Generated states 269175.\n",
      "=====================\n",
      "Player 2\n",
      "Select action: (1, 1)\n",
      "[[1 0 0]\n",
      " [0 2 0]\n",
      " [0 0 0]]\n",
      "Generated states 26853.\n",
      "=====================\n",
      "Player 1\n",
      "Select action: (0, 1)\n",
      "[[1 1 0]\n",
      " [0 2 0]\n",
      " [0 0 0]]\n",
      "Generated states 2425.\n",
      "=====================\n",
      "Player 2\n",
      "Select action: (0, 2)\n",
      "[[1 1 2]\n",
      " [0 2 0]\n",
      " [0 0 0]]\n",
      "Generated states 77.\n",
      "=====================\n",
      "Player 1\n",
      "Select action: (2, 0)\n",
      "[[1 1 2]\n",
      " [0 2 0]\n",
      " [1 0 0]]\n",
      "Generated states 66.\n",
      "=====================\n",
      "Player 2\n",
      "Select action: (1, 0)\n",
      "[[1 1 2]\n",
      " [2 2 0]\n",
      " [1 0 0]]\n",
      "Generated states 17.\n",
      "=====================\n",
      "Player 1\n",
      "Select action: (1, 2)\n",
      "[[1 1 2]\n",
      " [2 2 1]\n",
      " [1 0 0]]\n",
      "Generated states 10.\n",
      "=====================\n",
      "Player 2\n",
      "Select action: (2, 1)\n",
      "[[1 1 2]\n",
      " [2 2 1]\n",
      " [1 2 0]]\n",
      "Generated states 5.\n",
      "=====================\n",
      "Player 1\n",
      "Select action: (2, 2)\n",
      "[[1 1 2]\n",
      " [2 2 1]\n",
      " [1 2 1]]\n",
      "Generated states 2.\n",
      "Drawn\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Check if the game is not over\n",
    "    game_result = state.terminal_test()\n",
    "    if game_result != 0:\n",
    "        print(f\"Winner is {game_result} \")\n",
    "        break\n",
    "\n",
    "    # Checking for drawn\n",
    "    if len(state.possible_actions()) == 0:\n",
    "        print(\"Drawn\")\n",
    "        break\n",
    "\n",
    "    # player move\n",
    "    print(f\"=====================\\nPlayer {state.player}\")\n",
    "    _, player_action = state.minmax(\"max\")\n",
    "    print(f\"Select action: {player_action}\")\n",
    "    state = state.expand(player_action)\n",
    "    print(state.gameplan)\n",
    "    print(f\"Generated states {State.generated}.\")\n",
    "    State.generated = 0\n",
    "\n",
    "    # switching the game to the other player\n",
    "    state.player = state.next_player()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745aa6db-3392-4292-ac06-f83a78fe624c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec51825-20ef-49bd-a4e3-9fe282e08f07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
